{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "firedrake:WARNING OMP_NUM_THREADS is not set or is set to a value greater than 1, we suggest setting OMP_NUM_THREADS=1 to improve performance\n",
      "/Users/mh522/firedrake/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from firedrake import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "def check_forward(E,nu,strain_tensor):\n",
    "    lmbda = E*nu/(1+nu)/(1-2*nu)\n",
    "    mu = E/2/(1+nu)\n",
    "    # lmbda*tr(eps(v))*Identity(d) + 2*mu*eps(v), 0.1 is the trace of eps(v)\n",
    "    s = lmbda*np.trace(strain_tensor)*np.eye(2) + 2*mu*strain_tensor\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fire version\n",
    "def get_dataset(ntrain, ntest):\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in tqdm(range(ntrain + ntest)):\n",
    "        # Randomly generate E and nu within given ranges\n",
    "        E = np.random.uniform(30e3, 90e3)  # Young's modulus in Pa\n",
    "        nu = np.random.uniform(0.1, 0.3)      # Poisson's ratio\n",
    "\n",
    "        # Generate diagonal elements\n",
    "        a11, a12, a22 = [np.random.uniform(-0.1, 0.1) for _ in range(3)]\n",
    "        # Construct the 2x2 matrix\n",
    "        strain = np.array([[a11, a12], [a12, a22]])\n",
    "        \n",
    "        # strain = project(as_tensor(strain), V_tensor)\n",
    "        # stress = forward_model(E, nu, strain)\n",
    "        stress = check_forward(E, nu, strain)\n",
    "        \n",
    "        # Flatten and concatenate [E, nu] and strain\n",
    "        input_data = np.hstack([E, nu, a11, a22, a12])\n",
    "        \n",
    "        X.append(input_data)\n",
    "        y.append([stress[0,0], stress[1,1], stress[0,1]])\n",
    "        # y.append([stress.dat.data[0,0,0], stress.dat.data[0,1,1], stress.dat.data[0,0,1]])\n",
    "    # print(y)\n",
    "    # Convert lists to numpy arrays\n",
    "    X_train, X_test = np.array(X[:ntrain]), np.array(X[ntrain:])\n",
    "    y_train, y_test = np.array(y[:ntrain]), np.array(y[ntrain:])\n",
    "    \n",
    "    np.save(\"data/datasets/linear_elasticity/X_train.npy\", X_train)\n",
    "    np.save(\"data/datasets/linear_elasticity/y_train.npy\", y_train)\n",
    "    np.save(\"data/datasets/linear_elasticity/X_test.npy\", X_test)\n",
    "    np.save(\"data/datasets/linear_elasticity/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:00<00:00, 24287.93it/s]\n"
     ]
    }
   ],
   "source": [
    "ntrain = 200\n",
    "ntest = 20\n",
    "get_dataset(ntrain, ntest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "X_train = np.load(\"data/datasets/linear_elasticity/X_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(\"data/datasets/linear_elasticity/X_test.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"data/datasets/linear_elasticity/y_train.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"data/datasets/linear_elasticity/y_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "X_train_norm = min_max_normalize(X_train)\n",
    "y_train_norm = min_max_normalize(y_train)\n",
    "X_test_norm = min_max_normalize(X_test)\n",
    "y_test_norm = min_max_normalize(y_test)\n",
    "\n",
    "# Standardization\n",
    "# Z-score Normalization (Standardization)\n",
    "def standardize(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    return (data - mean) / std\n",
    "\n",
    "X_train_norm = standardize(X_train)\n",
    "y_train_norm = standardize(y_train)\n",
    "X_test_norm = standardize(X_test)\n",
    "y_test_norm = standardize(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MLP_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_model, self).__init__()\n",
    "        \n",
    "        # Define your model architecture\n",
    "        self.fc1 = nn.Linear(5, 5)  # Input size is 6\n",
    "        self.fc2 = nn.Linear(5, 3)  # Output size is 4\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = self.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Extract the upper triangle of the matrix\n",
    "def extract_upper_triangle(matrix):\n",
    "    indices = np.triu_indices(matrix.shape[1])\n",
    "    return matrix[:, indices[0], indices[1]]\n",
    "\n",
    "# Training function\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=2000, lr=0.00025):\n",
    "    # Convert data to PyTorch tensors and extract upper triangle\n",
    "    X_train_tensor = torch.tensor(extract_upper_triangle(X_train), dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(extract_upper_triangle(y_train), dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(extract_upper_triangle(X_test), dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(extract_upper_triangle(y_test), dtype=torch.float32)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        model.train()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            test_loss = criterion(test_outputs, y_test_tensor)\n",
    "            test_losses.append(test_loss.item())\n",
    "        # Print loss every 10 epochs\n",
    "        # if (epoch+1) % 10 == 0:\n",
    "            # print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    # Print final loss\n",
    "    print(f'Final loss: {loss.item():.4f}')\n",
    "    print(f'Final test loss: {test_loss.item():.4f}')\n",
    "    plt.plot(test_losses)\n",
    "    plt.plot(losses)\n",
    "    # Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y_test_norm \u001b[39m=\u001b[39m standardize(y_test)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m train_model(model, X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_test, y_test, epochs, lr)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model, X_train, y_train, X_test, y_test, epochs\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m0.00025\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[39m# Convert data to PyTorch tensors and extract upper triangle\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     X_train_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(extract_upper_triangle(X_train), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     15\u001b[0m     y_train_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(extract_upper_triangle(y_train), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     16\u001b[0m     X_test_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(extract_upper_triangle(X_test), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mextract_upper_triangle\u001b[0;34m(matrix)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_upper_triangle\u001b[39m(matrix):\n\u001b[1;32m      8\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtriu_indices(matrix\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m matrix[:, indices[\u001b[39m0\u001b[39;49m], indices[\u001b[39m1\u001b[39;49m]]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = MLP_model()\n",
    "\n",
    "# Standardize the data\n",
    "X_train_norm = standardize(X_train)\n",
    "y_train_norm = standardize(y_train)\n",
    "X_test_norm = standardize(X_test)\n",
    "y_test_norm = standardize(y_test)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m     \u001b[39m# 训练模型 (使用 train_loader)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     model\u001b[39m.\u001b[39mtrain()  \u001b[39m# 将模型设为训练模式\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     20\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "# 初始化\n",
    "model = MLP_model()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_val_loss = float('inf')  # 初始化为正无穷\n",
    "\n",
    "save_path = \"best_model.pth\"\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # 训练模型 (使用 train_loader)\n",
    "    model.train()  # 将模型设为训练模式\n",
    "    for batch_idx, (inputs, targets) in enumerate(X_train):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 在验证集上验证模型 (使用 test_loader)\n",
    "    model.eval()  # 将模型设为评估模式\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():  # 在评估模式下，我们不需要计算梯度\n",
    "        for inputs, targets in X_test:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(test_loader)  # 计算平均验证损失\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # 检查是否是最佳模型并保存\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
